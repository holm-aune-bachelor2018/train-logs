/home/anitakau/envs/tensorflow-workq/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2018-05-09 12:21:50.944638: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-05-09 12:21:52.454511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:03:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-05-09 12:21:52.623783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 1 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:82:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-05-09 12:21:52.623876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0, 1
2018-05-09 12:21:53.144377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-09 12:21:53.144424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 1 
2018-05-09 12:21:53.144433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N N 
2018-05-09 12:21:53.144437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 1:   N N 
2018-05-09 12:21:53.145099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:03:00.0, compute capability: 6.0)
2018-05-09 12:21:53.292551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15133 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:82:00.0, compute capability: 6.0)

Reading training data:
('Reading csv:', '/home/anitakau/ctc/data_dir/librivox-train-clean-360.csv')
Finished reading in data
removing any sentences that are too big- tweetsize
('Total number of files:', 104014)
('Total number of files (after reduction):', 102100)
('max_intseq_length:', 280)
('numclasses:', 29)
('max_trans_charlength:', 280)
('Words:', 3490549)
('Vocab:', 59235)

Reading validation data: 
('Reading csv:', '/home/anitakau/ctc/data_dir/librivox-dev-clean.csv')
Finished reading in data
removing any sentences that are too big- tweetsize
('Total number of files:', 2703)
('Total number of files (after reduction):', 2616)
('max_intseq_length:', 279)
('numclasses:', 29)
('max_trans_charlength:', 279)
('Words:', 48972)
('Vocab:', 7726)

Reading test data: 
('Reading csv:', '/home/anitakau/ctc/data_dir/librivox-test-clean.csv')
Finished reading in data
removing any sentences that are too big- tweetsize
('Total number of files:', 2620)
('Total number of files (after reduction):', 2526)
('max_intseq_length:', 280)
('numclasses:', 29)
('max_trans_charlength:', 280)
('Words:', 46839)
('Vocab:', 7547)


Model and training parameters: 
Starting time:  2018-05-09 12:21:48
 - epochs:  100 
 - batch size:  64 
 - input epoch length:  1024 
 - network epoch length:  1024 
 - training on  65536  files 
 - learning rate:  0.0001 
 - hidden units:  512 
 - mfcc features:  26 
 - dropout:  0.2 

Creating new model:  deep_rnn
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
the_input (InputLayer)          (None, None, 26)     0                                            
__________________________________________________________________________________________________
masking (Masking)               (None, None, 26)     0           the_input[0][0]                  
__________________________________________________________________________________________________
fc_1 (TimeDistributed)          (None, None, 512)    13824       masking[0][0]                    
__________________________________________________________________________________________________
dropout_1 (TimeDistributed)     (None, None, 512)    0           fc_1[0][0]                       
__________________________________________________________________________________________________
fc_2 (TimeDistributed)          (None, None, 512)    262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (TimeDistributed)     (None, None, 512)    0           fc_2[0][0]                       
__________________________________________________________________________________________________
fc_3 (TimeDistributed)          (None, None, 512)    262656      dropout_2[0][0]                  
__________________________________________________________________________________________________
dropout_3 (TimeDistributed)     (None, None, 512)    0           fc_3[0][0]                       
__________________________________________________________________________________________________
deep_rnn_1 (SimpleRNN)          (None, None, 512)    524800      dropout_3[0][0]                  
__________________________________________________________________________________________________
deep_rnn_2 (SimpleRNN)          (None, None, 512)    524800      deep_rnn_1[0][0]                 
__________________________________________________________________________________________________
deep_rnn_3 (SimpleRNN)          (None, None, 512)    524800      deep_rnn_2[0][0]                 
__________________________________________________________________________________________________
fc_4 (TimeDistributed)          (None, None, 512)    262656      deep_rnn_3[0][0]                 
__________________________________________________________________________________________________
dropout_4 (TimeDistributed)     (None, None, 512)    0           fc_4[0][0]                       
__________________________________________________________________________________________________
softmax (TimeDistributed)       (None, None, 29)     14877       dropout_4[0][0]                  
__________________________________________________________________________________________________
the_labels (InputLayer)         (None, None)         0                                            
__________________________________________________________________________________________________
input_length (InputLayer)       (None, 1)            0                                            
__________________________________________________________________________________________________
label_length (InputLayer)       (None, 1)            0                                            
__________________________________________________________________________________________________
ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    
                                                                 the_labels[0][0]                 
                                                                 input_length[0][0]               
                                                                 label_length[0][0]               
==================================================================================================
Total params: 2,391,069
Trainable params: 2,391,069
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/100
 - 2994s - loss: 506.6473 - val_loss: 255.4222

Epoch 00001: val_loss improved from inf to 255.42216, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.991517857143
Epoch 2/100
 - 2896s - loss: 311.0296 - val_loss: 189.2466

Epoch 00002: val_loss improved from 255.42216 to 189.24657, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.95939360119
Epoch 3/100
 - 2896s - loss: 267.2631 - val_loss: 162.7221

Epoch 00003: val_loss improved from 189.24657 to 162.72209, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.898567708333
Epoch 4/100
 - 2899s - loss: 242.4224 - val_loss: 140.3669

Epoch 00004: val_loss improved from 162.72209 to 140.36688, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.901432291667
Epoch 5/100
 - 2899s - loss: 224.3847 - val_loss: 128.1478

Epoch 00005: val_loss improved from 140.36688 to 128.14777, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.891889880952
Epoch 6/100
 - 2896s - loss: 210.7643 - val_loss: 121.1875

Epoch 00006: val_loss improved from 128.14777 to 121.18747, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.869642857143
Epoch 7/100
 - 2893s - loss: 199.8014 - val_loss: 112.7906

Epoch 00007: val_loss improved from 121.18747 to 112.79060, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.842150297619
Epoch 8/100
 - 2895s - loss: 190.8393 - val_loss: 105.9384

Epoch 00008: val_loss improved from 112.79060 to 105.93838, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.814415922619
Epoch 9/100
 - 2900s - loss: 183.0430 - val_loss: 102.4207

Epoch 00009: val_loss improved from 105.93838 to 102.42073, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.831863839286
Epoch 10/100
 - 2894s - loss: 176.5722 - val_loss: 99.0032

Epoch 00010: val_loss improved from 102.42073 to 99.00322, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.815959821429
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 11/100
 - 2895s - loss: 170.8582 - val_loss: 95.3091

Epoch 00011: val_loss improved from 99.00322 to 95.30915, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.816499255952
Epoch 12/100
 - 2900s - loss: 165.6475 - val_loss: 91.2981

Epoch 00012: val_loss improved from 95.30915 to 91.29812, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.742336309524
Epoch 13/100
 - 2893s - loss: 160.9379 - val_loss: 89.6898

Epoch 00013: val_loss improved from 91.29812 to 89.68979, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.740271577381
Epoch 14/100
 - 2895s - loss: 156.5253 - val_loss: 86.5027

Epoch 00014: val_loss improved from 89.68979 to 86.50269, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.740904017857
Epoch 15/100
 - 2896s - loss: 152.8384 - val_loss: 84.8442

Epoch 00015: val_loss improved from 86.50269 to 84.84423, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.733203125
Epoch 16/100
 - 2894s - loss: 149.2811 - val_loss: 83.0667

Epoch 00016: val_loss improved from 84.84423 to 83.06670, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.743266369048
Epoch 17/100
 - 2895s - loss: 146.1204 - val_loss: 81.1193

Epoch 00017: val_loss improved from 83.06670 to 81.11933, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.711439732143
Epoch 18/100
 - 2891s - loss: 143.2577 - val_loss: 78.9934

Epoch 00018: val_loss improved from 81.11933 to 78.99342, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.684691220238
Epoch 19/100
 - 2893s - loss: 140.5070 - val_loss: 77.6894

Epoch 00019: val_loss improved from 78.99342 to 77.68940, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.700446428571
Epoch 20/100
 - 2894s - loss: 137.9279 - val_loss: 76.8063

Epoch 00020: val_loss improved from 77.68940 to 76.80632, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.715718005952
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 21/100
 - 2891s - loss: 135.5777 - val_loss: 75.7671

Epoch 00021: val_loss improved from 76.80632 to 75.76713, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.662053571429
Epoch 22/100
 - 2895s - loss: 133.4466 - val_loss: 73.9215

Epoch 00022: val_loss improved from 75.76713 to 73.92154, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.684709821429
Epoch 23/100
 - 2893s - loss: 131.3865 - val_loss: 73.0837

Epoch 00023: val_loss improved from 73.92154 to 73.08373, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.687965029762
Epoch 24/100
 - 2891s - loss: 129.5111 - val_loss: 71.5286

Epoch 00024: val_loss improved from 73.08373 to 71.52857, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.664248511905
Epoch 25/100
 - 2893s - loss: 127.8379 - val_loss: 71.3473

Epoch 00025: val_loss improved from 71.52857 to 71.34734, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.659170386905
Epoch 26/100
 - 2895s - loss: 126.2073 - val_loss: 70.2121

Epoch 00026: val_loss improved from 71.34734 to 70.21211, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.640513392857
Epoch 27/100
 - 2892s - loss: 124.5781 - val_loss: 69.4914

Epoch 00027: val_loss improved from 70.21211 to 69.49136, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.599386160714
Epoch 28/100
 - 2890s - loss: 122.9710 - val_loss: 67.6424

Epoch 00028: val_loss improved from 69.49136 to 67.64241, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.641908482143
Epoch 29/100
 - 2889s - loss: 121.5703 - val_loss: 67.4970

Epoch 00029: val_loss improved from 67.64241 to 67.49697, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.628087797619
Epoch 30/100
 - 2890s - loss: 120.1529 - val_loss: 66.5218

Epoch 00030: val_loss improved from 67.49697 to 66.52179, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.623697916667
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 31/100
 - 2891s - loss: 118.9585 - val_loss: 67.1360

Epoch 00031: val_loss did not improve
 - average WER:  0.608240327381
Epoch 32/100
 - 2890s - loss: 117.6110 - val_loss: 65.5497

Epoch 00032: val_loss improved from 66.52179 to 65.54973, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.628199404762
Epoch 33/100
 - 2893s - loss: 116.3127 - val_loss: 65.1152

Epoch 00033: val_loss improved from 65.54973 to 65.11522, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.607924107143
Epoch 34/100
 - 2894s - loss: 115.3312 - val_loss: 63.9823

Epoch 00034: val_loss improved from 65.11522 to 63.98227, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.613932291667
Epoch 35/100
 - 2890s - loss: 114.2621 - val_loss: 63.4911

Epoch 00035: val_loss improved from 63.98227 to 63.49112, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.614918154762
Epoch 36/100
 - 2890s - loss: 113.1407 - val_loss: 62.8281

Epoch 00036: val_loss improved from 63.49112 to 62.82811, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.63439360119
Epoch 37/100
 - 2890s - loss: 112.2233 - val_loss: 62.0506

Epoch 00037: val_loss improved from 62.82811 to 62.05059, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.582756696429
Epoch 38/100
 - 2892s - loss: 111.3241 - val_loss: 62.0150

Epoch 00038: val_loss improved from 62.05059 to 62.01500, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.616090029762
Epoch 39/100
 - 2894s - loss: 110.4160 - val_loss: 61.5584

Epoch 00039: val_loss improved from 62.01500 to 61.55840, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.59689360119
Epoch 40/100
 - 2893s - loss: 109.4630 - val_loss: 61.8872

Epoch 00040: val_loss did not improve
 - average WER:  0.616666666667
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 41/100
 - 2889s - loss: 108.4447 - val_loss: 59.9385

Epoch 00041: val_loss improved from 61.55840 to 59.93850, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.596707589286
Epoch 42/100
 - 2893s - loss: 107.7636 - val_loss: 59.9820

Epoch 00042: val_loss did not improve
 - average WER:  0.596409970238
Epoch 43/100
 - 2892s - loss: 106.9642 - val_loss: 60.0878

Epoch 00043: val_loss did not improve
 - average WER:  0.590662202381
Epoch 44/100
 - 2896s - loss: 106.2440 - val_loss: 59.2689

Epoch 00044: val_loss improved from 59.93850 to 59.26886, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.603757440476
Epoch 45/100
 - 2893s - loss: 105.5477 - val_loss: 58.7850

Epoch 00045: val_loss improved from 59.26886 to 58.78504, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.572302827381
Epoch 46/100
 - 2888s - loss: 104.8047 - val_loss: 59.0417

Epoch 00046: val_loss did not improve
 - average WER:  0.573400297619
Epoch 47/100
 - 2895s - loss: 104.2837 - val_loss: 58.4586

Epoch 00047: val_loss improved from 58.78504 to 58.45855, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.555040922619
Epoch 48/100
 - 2894s - loss: 103.3739 - val_loss: 57.5446

Epoch 00048: val_loss improved from 58.45855 to 57.54457, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.588988095238
Epoch 49/100
 - 2890s - loss: 102.8478 - val_loss: 57.5326

Epoch 00049: val_loss improved from 57.54457 to 57.53261, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.572953869048
Epoch 50/100
 - 2891s - loss: 102.0284 - val_loss: 57.1871

Epoch 00050: val_loss improved from 57.53261 to 57.18705, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.574255952381
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 51/100
 - 2889s - loss: 101.5912 - val_loss: 57.1634

Epoch 00051: val_loss improved from 57.18705 to 57.16337, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.581212797619
Epoch 52/100
 - 2888s - loss: 100.9445 - val_loss: 56.4247

Epoch 00052: val_loss improved from 57.16337 to 56.42471, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.545926339286
Epoch 53/100
 - 2893s - loss: 100.2612 - val_loss: 57.1526

Epoch 00053: val_loss did not improve
 - average WER:  0.549683779762
Epoch 54/100
 - 2891s - loss: 99.6922 - val_loss: 56.3980

Epoch 00054: val_loss improved from 56.42471 to 56.39796, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.573511904762
Epoch 55/100
 - 2892s - loss: 99.3084 - val_loss: 55.7652

Epoch 00055: val_loss improved from 56.39796 to 55.76522, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.51677827381
Epoch 56/100
 - 2891s - loss: 98.9175 - val_loss: 56.0473

Epoch 00056: val_loss did not improve
 - average WER:  0.563895089286
Epoch 57/100
 - 2890s - loss: 98.3367 - val_loss: 55.8621

Epoch 00057: val_loss did not improve
 - average WER:  0.543266369048
Epoch 58/100
 - 2891s - loss: 97.8789 - val_loss: 55.0334

Epoch 00058: val_loss improved from 55.76522 to 55.03338, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.562686011905
Epoch 59/100
 - 2892s - loss: 97.2706 - val_loss: 55.5861

Epoch 00059: val_loss did not improve
 - average WER:  0.569066220238
Epoch 60/100
 - 2890s - loss: 96.7399 - val_loss: 54.4184

Epoch 00060: val_loss improved from 55.03338 to 54.41838, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.566982886905
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 61/100
 - 2893s - loss: 96.3664 - val_loss: 54.6647

Epoch 00061: val_loss did not improve
 - average WER:  0.568805803571
Epoch 62/100
 - 2890s - loss: 95.9495 - val_loss: 53.9422

Epoch 00062: val_loss improved from 54.41838 to 53.94216, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.54138764881
Epoch 63/100
 - 2887s - loss: 95.5444 - val_loss: 53.8682

Epoch 00063: val_loss improved from 53.94216 to 53.86824, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.559691220238
Epoch 64/100
 - 2892s - loss: 95.1141 - val_loss: 54.1480

Epoch 00064: val_loss did not improve
 - average WER:  0.526674107143
Epoch 65/100
 - 2891s - loss: 94.7384 - val_loss: 53.1697

Epoch 00065: val_loss improved from 53.86824 to 53.16966, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.543991815476
Epoch 66/100
 - 2889s - loss: 94.1449 - val_loss: 53.2638

Epoch 00066: val_loss did not improve
 - average WER:  0.55040922619
Epoch 67/100
 - 2889s - loss: 93.8068 - val_loss: 52.9156

Epoch 00067: val_loss improved from 53.16966 to 52.91561, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.509523809524
Epoch 68/100
 - 2891s - loss: 93.4915 - val_loss: 53.4642

Epoch 00068: val_loss did not improve
 - average WER:  0.625706845238
Epoch 69/100
 - 2889s - loss: 93.1799 - val_loss: 52.8523

Epoch 00069: val_loss improved from 52.91561 to 52.85231, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.535323660714
Epoch 70/100
 - 2888s - loss: 92.7503 - val_loss: 52.3453

Epoch 00070: val_loss improved from 52.85231 to 52.34527, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.562667410714
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 71/100
 - 2888s - loss: 92.3914 - val_loss: 52.4829

Epoch 00071: val_loss did not improve
 - average WER:  0.541257440476
Epoch 72/100
 - 2891s - loss: 92.1272 - val_loss: 52.2817

Epoch 00072: val_loss improved from 52.34527 to 52.28168, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.555989583333
Epoch 73/100
 - 2889s - loss: 91.6373 - val_loss: 52.3107

Epoch 00073: val_loss did not improve
 - average WER:  0.541294642857
Epoch 74/100
 - 2892s - loss: 91.2742 - val_loss: 52.2123

Epoch 00074: val_loss improved from 52.28168 to 52.21228, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.520870535714
Epoch 75/100
 - 2887s - loss: 90.8938 - val_loss: 51.8483

Epoch 00075: val_loss improved from 52.21228 to 51.84826, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.518396577381
Epoch 76/100
 - 2889s - loss: 90.5941 - val_loss: 51.6692

Epoch 00076: val_loss improved from 51.84826 to 51.66920, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.521391369048
Epoch 77/100
 - 2889s - loss: 90.4111 - val_loss: 51.6312

Epoch 00077: val_loss improved from 51.66920 to 51.63119, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.546261160714
Epoch 78/100
 - 2889s - loss: 90.0463 - val_loss: 51.2166

Epoch 00078: val_loss improved from 51.63119 to 51.21664, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.538318452381
Epoch 79/100
 - 2889s - loss: 89.5227 - val_loss: 51.1632

Epoch 00079: val_loss improved from 51.21664 to 51.16320, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.502845982143
Epoch 80/100
 - 2885s - loss: 89.3367 - val_loss: 51.7762

Epoch 00080: val_loss did not improve
 - average WER:  0.550613839286
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 81/100
 - 2887s - loss: 89.0214 - val_loss: 50.6865

Epoch 00081: val_loss improved from 51.16320 to 50.68652, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.52068452381
Epoch 82/100
 - 2890s - loss: 88.7658 - val_loss: 50.5358

Epoch 00082: val_loss improved from 50.68652 to 50.53584, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.504910714286
Epoch 83/100
 - 2888s - loss: 88.5901 - val_loss: 50.2512

Epoch 00083: val_loss improved from 50.53584 to 50.25117, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.526302083333
Epoch 84/100
 - 2886s - loss: 88.2294 - val_loss: 50.8069

Epoch 00084: val_loss did not improve
 - average WER:  0.534523809524
Epoch 85/100
 - 2892s - loss: 87.9185 - val_loss: 49.8873

Epoch 00085: val_loss improved from 50.25117 to 49.88732, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.521205357143
Epoch 86/100
 - 2889s - loss: 87.8493 - val_loss: 49.7733

Epoch 00086: val_loss improved from 49.88732 to 49.77330, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.526376488095
Epoch 87/100
 - 2890s - loss: 87.6522 - val_loss: 49.7283

Epoch 00087: val_loss improved from 49.77330 to 49.72834, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.504743303571
Epoch 88/100
 - 2889s - loss: 87.4053 - val_loss: 49.7554

Epoch 00088: val_loss did not improve
 - average WER:  0.525241815476
Epoch 89/100
 - 2887s - loss: 86.8307 - val_loss: 49.6362

Epoch 00089: val_loss improved from 49.72834 to 49.63618, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.550502232143
Epoch 90/100
 - 2889s - loss: 86.6836 - val_loss: 50.0418

Epoch 00090: val_loss did not improve
 - average WER:  0.515625
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
Epoch 91/100
 - 2885s - loss: 86.5242 - val_loss: 49.7120

Epoch 00091: val_loss did not improve
 - average WER:  0.482924107143
Epoch 92/100
 - 2896s - loss: 86.4983 - val_loss: 49.5678

Epoch 00092: val_loss improved from 49.63618 to 49.56776, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.523325892857
Epoch 93/100
 - 2888s - loss: 85.8916 - val_loss: 49.4785

Epoch 00093: val_loss improved from 49.56776 to 49.47846, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.466908482143
Epoch 94/100
 - 2888s - loss: 85.7182 - val_loss: 49.8770

Epoch 00094: val_loss did not improve
 - average WER:  0.523102678571
Epoch 95/100
 - 2889s - loss: 85.5210 - val_loss: 49.1128

Epoch 00095: val_loss improved from 49.47846 to 49.11281, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.496949404762
Epoch 96/100
 - 2888s - loss: 85.2624 - val_loss: 49.4403

Epoch 00096: val_loss did not improve
 - average WER:  0.511923363095
Epoch 97/100
 - 2883s - loss: 85.1853 - val_loss: 50.2160

Epoch 00097: val_loss did not improve
 - average WER:  0.523660714286
Epoch 98/100
 - 2892s - loss: 84.8575 - val_loss: 50.1807

Epoch 00098: val_loss did not improve
 - average WER:  0.53984375
Epoch 99/100
 - 2892s - loss: 84.4700 - val_loss: 48.8335

Epoch 00099: val_loss improved from 49.11281 to 48.83351, saving model to modelssave/0905-deep-rnn-60_best
 - average WER:  0.509040178571
Epoch 100/100
 - 2890s - loss: 84.4305 - val_loss: 48.8400

Epoch 00100: val_loss did not improve
 - average WER:  0.512630208333
Log file saved:  log_files/0905-deep-rnn-60_05-09_1221.csv
An exception of type ValueError occurred. Arguments:
('max() arg is an empty sequence',)
Ending time:  2018-05-12 20:44:59
